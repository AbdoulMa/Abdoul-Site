---
title: "Club Predictions"
description: |
  Scraping of european clubs predictions and visualization of championship winning           probabilities.
author:
  - name: Abdoul ISSA BIDA
    url: {}
date: 09-03-2021
preview: preview.png
output:
  distill::distill_article:
    self_contained: false
categories: 
 - R 
 - Tidyverse
 - Soccer
 - Scraping
citation_url: https://abdoulblog.netlify.app
bibliography: ../articles.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
# TODO Set data GH link 
library(rvest)     
library(xml2)
library(tidyverse)
library(waffle)
library(ggtext)
library(ragg)
library(kableExtra)
library(janitor)
```

Hi everyone and welcome in my second blog post.

For this one, we will cover together two of my favorite disciplines, one in Computer Science, Scraping and the other one in real life, Soccer .

Don't be disappointed `r emo::ji('smile')`, if you are there only for the final dataviz, you can skip to the next section. I tried to make it as much as clear and simple that I can.

# Scraping 

So, what website we are going to scrape ? 

It will be [FiveThirtyEight](https://projects.fivethirtyeight.com). They provide data behind some of their articles and charts, including data for Soccer Clubs Predictions. 

Unfortunately, the data you can retrieve only  cover for [Club Soccer Predictions](https://projects.fivethirtyeight.com/soccer-predictions/) and [Global Club Soccer Rankings](https://projects.fivethirtyeight.com/global-club-soccer-rankings/). But for our today tutorial, based mostly  on determining which league club will qualify for UCL^[UEFA Champions League] or which will win the national league. 

So, we will scrape it directly, from the league page. For example, to scrape, the probabilities that each club of: 

- French Ligue 1, we will scrape it from [https://projects.fivethirtyeight.com/soccer-predictions/ligue-1/]()
- German Bundesliga, we will scrape it from [https://projects.fivethirtyeight.com/soccer-predictions/bundesliga/]() 
- English Premier League, we will scrape it from [https://projects.fivethirtyeight.com/soccer-predictions/premier-league/]()
- and so on. 

Here is an example of how, the data is presented on their website. 

```{r site_presentation, echo = F}
knitr::include_url(url = "https://projects.fivethirtyeight.com/soccer-predictions/premier-league/", height = 450)
```

The data is updated daily, what is very interesting because, with some tricky automation, we can follow the evolution of the odds of the clubs  to win a season along. But, that is not the subject of this blog post.

## Website Page Reading 

For the scraping, we need a couple libraries, in particular: 

```{r load_scrap_library, eval = F}
library(tidyverse) # For data wrangling, ggplot2 and friends
library(rvest) # for the scraping 
library(janitor) # for the function row_to_names
```

So, let's start our scraping workflow : 

```{r scrap_forecast_tab}
league_link <- "https://projects.fivethirtyeight.com/soccer-predictions/premier-league/"
clubs_rows <- league_link %>% 
  read_html() %>% # Retrieve the complete table 
  html_element("#forecast-table") %>%  # Retrieve only the forecast table
  html_elements("tbody .team-row") # Retrieve each row of the table
```

Let's me explain a little bit the code. 

Firstly,  I retrieve the complete page.

```{r, eval = F}
league_link %>% 
  read_html()
```

Secondly, I retrieve the forecasting table, with the function `html_element()`. So, where `#forecast-table` comes from? 

To be a good, web scraper, you must be a good website  inspector. Web developers, create websites with logic, and in order to retrieve data from those website pages, we have to make to make us their logic. 

To find out how to access the forecast table, you must go to the page we are scraping ([here](https://projects.fivethirtyeight.com/soccer-predictions/premier-league/)). `Right-click` on the table we want to retrieve, and then click `inspect`. The browser will open the `inspector`. 

```{r inspector, echo=F, out.width='100%', fig.cap='Inspector Interface'}
knitr::include_graphics("inspector.png", dpi = 640)
```

<aside>
I use Mozilla Firefox as my browser, you will probably need another process depending on your browser. Google it, if you don't know how to do it.
</aside>

Next, you need a little  attention to notice that the table has as `id` `forecast-table`. It also has as `class` `forecast-table`. But, we will use the `id` to access the table. 

For this,  we use the `html_element()` function of the `rvest`[@rvest] package.
When we select the table by its `id`, we prefix the `id` with `#` in our `html_element()` function. 

In the same way, we collect each club row with:

```{r, eval = F}
... %>% 
html_elements("tbody .team-row")
```

Note that we are using, `html_elements()` instead of `html_element()`, which selects all the elements (and not just the first one) our forecast table.

Let's see what the list of results looks like. 

```{r clubs_list}
clubs_rows
```

Well, we have all, the premier league clubs.

## Clubs names and logos 

The next step in my workflow is to select for each club, its name and logo link. 
You should be wondering, why  I am not selecting the probabilities I was talking at the beginning. Please be patient, this will be the subject of our next section.

Let's get the name and the logo for one club, and then generalize for all. 

```{r individual_name_logo_selection}
# Let's select the first node 
node <- pluck(clubs_rows, 1)
 team_name <- node %>% 
    html_element(".team-div .name") %>% # Select Team name elmt
    html_text2() %>% # Retrieve the text
    # Delete the points in the name
    # Example: Man City8pts becomes Man City
    str_remove(pattern ="\\d+\\spts?") 
  
  team_logo <- node %>% 
    # Select Team the img which contains team logo
    html_element(".logo img") %>% 
    # Retrieve the the src attribute
    html_attr("src") %>% 
    str_remove("&w=56")
```

Let's see if everything is what it supposed to.


```{r}
print(team_name)
```
```{r}
print(team_logo)
```

It is perfect, we can  recorver from a node, the club name and its logo. Let us generalize to all the clubs with a function. 

```{r generalized_names_logos_selection}
extract_name_logo <- function(node) { 
  team_name <- node %>% 
    html_element(".team-div .name") %>% # Select Team name element
    html_text2() %>% # Retrieve the text
    # Delete the points in the name
    # Example: "Man City8pts" becomes "Man City"
    str_remove(pattern ="\\d+\\spts?") 
  
  team_logo <- node %>% 
    # Select the img element which contains team logo
    html_element(".logo img") %>% 
    # Retrieve the the src attribute
    html_attr("src") %>% 
    str_remove("&w=56")
  # Return it like a tibble
  tibble(
    team_name,
    team_logo
  ) 
}
```

Thanks to the `purrr`  library, we can now retrieve all  clubs names and logos. 

```{r}
clubs_names_logos <- clubs_rows %>% 
   map_df(extract_name_logo)
```


```{r , echo=F, fig.align='center'}
  clubs_names_logos %>% 
  kable(format = "html", caption='Team names and logos link') %>% 
  kable_styling(position = "center")
```

## Retrieve the forecast table 

In this section, we will use another function from  `rvest` package : `html_table()`. 
This function mimics what what  a browser does, but repeats the values of merged cells in every cell that cover. 

```{r clubs_predictions_table}
clubs_predictions <- league_link %>% 
  read_html() %>% 
  html_element("#forecast-table") %>% 
  # Don't keep the header 
  html_table(header = F) %>% 
  # Remove extra headers that we don't need
  # And make 
  janitor::row_to_names(row_number = 3) %>%
  # Remove extra columns that we don't need
  select(1:10) %>% 
  # Separate team name  team point 
  # they are seperated by a tag in the hmtl 
  # and collapsed if retrieved by html_page 
  tidyr::extract(col = team, into = c('team_name','team_point'), regex = "(.+)(\\d+\\spts?)") 
```

I know it can be a little bit complex for a beginner (6 months ago I was too). But nothing exceptional, if you understand the logic behind each function. 

What the data looks like at this stage? 

```{r,  echo= F}
clubs_predictions %>% 
  kable(format = "html", caption = "Clubs Predictions") %>% 
  kable_styling(position = "center")
```

Let's clean the data a bit more the data to  make it fit what we want to do. 

```{r predictions_data_cleaning}
clubs_predictions <- clubs_predictions %>%
  # the column with "win league" has different
  # name according to the league so I rename it
  # to "win_league" for all leagues
  mutate(across(contains("win league"), ~ ., .names = "win_league")) %>%
  # Rename important columns
  rename(goal_diff = "goal diff.",
         proj_pts = "proj. pts.pts.",
         qualify_ucl = "qualify for UCLmake UCL"
  ) %>%
  # Delete column with space
  select(-contains(" "))

# When probability <1%, give  it 0
clubs_predictions <- clubs_predictions %>%
  mutate(across(.cols = c("relegatedrel.", "qualify_ucl", "win_league"), .fns = ~ if_else(. == "<1%", "0", .))) %>%
  mutate(across(.cols = c("relegatedrel.", "qualify_ucl", "win_league"), .fns = ~ parse_number(.)))
```

Finally, let's join the `clubs predictions dataframe` with `names and logos dataframe` previously scraped.  

```{r predictions_data_join}
clubs_predictions <- clubs_predictions %>%
  left_join(clubs_names_logos)
```
<div style ="width:100%; display:block; overflow:auto;">

```{r echo=F}
clubs_predictions %>% 
  head(5) %>% 
  kable(format = 'html', caption = "Clubs Predictions and Teams Informations") %>% 
  kable_styling(position = 'center')

write_csv(clubs_predictions,"epl_clubs_predictions.csv")
```
</div>


# Data Visualization 

Well, we had our data, tidy as we wanted. Now let's visualize it. 
If you skip the scraping workflow, you can download the data for this section [here]().

We are going to visualize it as a facet of a waffle plot for each team. 
Since the probabilities are represented as percentage, we are going to make a waffle of 100 squares.
Each represents a chance for a club to win the league, to qualify for UEFA Champions League or both. 

However, to fill the square according to each category of probability, it is necessary to wrangle the data a little bit more, in particular to bring together in a single column the three categories we want to highlight. 

So what do I do? 

```{r}
predictions_waffle_df <- clubs_predictions %>% 
  mutate(ucl_qualif_diff = qualify_ucl - win_league,
         remaining = 100 - qualify_ucl) %>% 
  pivot_longer(
    cols = c("win_league", "ucl_qualif_diff","remaining"), 
    names_to = "win_cat", 
    values_to = "win_value"
  )
```

First, I create  two new columns: 

- `ucl_qualif_diff`  which represents the probability that a club qualifies to UEFA Champions League 
- `remaining` which represents the probability that a club won't win the league and won't qualify for the UEFA Champions League. 

And Finally, i am grouping my three categories into a single column `win_cat` and their values in the  `win_value` column.

So let's finally make the waffle. 

We will be using [`waffle`](https://github.com/hrbrmstr/waffle) package by Bob Rudis, which is clearly one of my favorites. 

Unfortunately, the package  is not available on CRAN, so let's install it with devtools: 

```{r install_waffle, eval=F}
devtools::install_github("hrbrmstr/waffle")
```

We will need a few more package to polish our visualization: 

```{r load_libraries, eval = F}
library(waffle)
library(ggtext) # For customize the text 
library(ragg) # For the device  to save the plot
```

To draw club logo images, let's define a special function: 

```{r logo_image}
# The function takes 2 parameters 
# x which refers to club logo link we scraped early  
# width for the img width with default value 30
link_to_img <- function(x, width = 30) {
  # Define the logo link as src attribute to 
  # html img element
  glue::glue("<img src='{x}' width='{width}'/>")
}
```

Finally let's implement our visualization.


```{r data_visualisation}
plot <- predictions_waffle_df %>% 
  mutate( team_name = fct_reorder(paste0(link_to_img(team_logo),'<br>',team_name), -qualify_ucl), 
    win_cat = fct_relevel(win_cat, c("win_league", "ucl_qualif_diff","remaining"))) %>% 
  ggplot(aes(fill = win_cat, values = win_value)) + 
  geom_waffle(color = "white", size = .15, n_rows = 10, flip = T) + 
  facet_wrap(vars(team_name)) + 
  scale_fill_manual(
    name = NULL,
    values = c(
      "win_league" = "#117733",
      "ucl_qualif_diff" = alpha("#117733",.5),
      "remaining" = alpha("#117733",.1)
    ) ,
    labels = 
      c(
        "win_league" = "Win League & Qualify to UCL",
        "ucl_qualif_diff" = "Qualify to UCL",
        "remaining" = "No chance"
      )
  ) +
  coord_equal(expand = F) + 
  theme_minimal(base_family = "Chivo") +
  theme(
    plot.background = element_rect(fill = "grey95", color = NA),
    panel.border = element_rect(color = "black", size = 1.1, fill = NA),
    legend.position = "top",
    plot.margin = margin( b = 1, unit = "cm"),
        axis.text = element_blank(),
        strip.text = element_markdown())
```


```{r, include=F}
ggsave("club_predictions.png", plot = plot, width = 9, height = 9.5, device = ragg::agg_png, dpi = 640) 
```


```{r, echo=F}
knitr::include_graphics(path = "club_predictions.png")
```

<div style="margin-top: 20px;text-align:center;font-weight:bold; font-size : 2.5rem !important;">Et voilà!</div>



